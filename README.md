# NYC Taxi Data Pipeline

Ce workflow GitHub Actions automatise le pipeline de donnÃ©es de bout en bout, depuis l'initialisation de l'infrastructure Snowflake jusqu'Ã  la production de tables et vues analytiques en utilisant python et dbt.
<br> <br>
<a href="https://eliasmez.github.io/nyc-taxi-pipeline">ğŸ“š Documentation complÃ¨te en ligne</a>
<br>

## ğŸ“Š Source des DonnÃ©es

[**TLC Trip Record Data**](https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page) - Commission des Taxis et Limousines de NYC

Les donnÃ©es incluent :

- Dates/heures de prise en charge et dÃ©pose
- Localisations GPS des trajets
- Distances, tarifs dÃ©taillÃ©s, types de paiement
- Nombre de passagers rapportÃ© par le chauffeur

*Les donnÃ©es sont collectÃ©es par les fournisseurs technologiques autorisÃ©s et fournies Ã  la TLC. La TLC ne garantit pas l'exactitude de ces donnÃ©es.*

## ğŸ“„ Licence

Ce projet est sous licence MIT. Les donnÃ©es source sont fournies par la [NYC TLC](https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page) et soumises Ã  leurs conditions d'utilisation.
<br>
<br>
<br>


# ğŸ›ï¸ Architecture

## ğŸ—ï¸ Architecture Technique

[![GitHub Actions](https://img.shields.io/badge/GitHub_Actions-2088FF?logo=github-actions&logoColor=white)]()
[![Snowflake](https://img.shields.io/badge/Snowflake-Data_Warehouse-29B5E8?logo=snowflake&logoColor=white)]()
[![Python](https://img.shields.io/badge/Python-3.10-3776AB?logo=python&logoColor=white)]()
[![dbt](https://img.shields.io/badge/dbt-Transformations-FF694B?logo=dbt&logoColor=white)]()

- **Orchestration** : GitHub Actions
- **Data Warehouse** : Snowflake
- **Transformation** : dbt
- **Langage** : Python
<br>

## ğŸ“ Structure du Projet
```bash
nyc-taxi-pipeline/
â”œâ”€â”€ .github/
â”‚ â”œâ”€â”€ workflows/
â”‚ â”‚ â”œâ”€â”€ nyc_taxi_pipeline.yml
â”‚ â”‚ â”œâ”€â”€ codeql.yml
â”‚ â”‚ â”œâ”€â”€ python_code_tests.yml
â”‚ â”‚ â”œâ”€â”€ release.yml
â”‚ â”‚ â””â”€â”€ sqlfluff.yml
â”‚ â”‚
â”‚ â””â”€â”€ dependabot.yml
â”‚
â”œâ”€â”€ docs/
â”‚
â”œâ”€â”€ snowflake_ingestion/
â”‚ â”œâ”€â”€ init_data_warehouse.py
â”‚ â”œâ”€â”€ scrape_links.py
â”‚ â”œâ”€â”€ upload_stage.py
â”‚ â”œâ”€â”€ load_to_table.py
â”‚ â”‚
â”‚ â”œâ”€â”€ sql/
â”‚ â”‚ â”œâ”€â”€ init/
â”‚ â”‚ â”œâ”€â”€ scraping/
â”‚ â”‚ â”œâ”€â”€ stage/
â”‚ â”‚ â””â”€â”€ load/
â”‚ â”‚
â”‚ â””â”€â”€ tests/
â”‚
â””â”€â”€ dbt_transformations/
  â””â”€â”€ NYC_Taxi_dbt/
    â””â”€â”€ models/
      â”œâ”€â”€ staging/
      â”œâ”€â”€ final/
      â””â”€â”€ marts/
```
<br>


## ğŸ“Š Flux de traitement

### Pipeline Principal :

**NYC Taxi Data Pipeline**  
Pipeline d'ingestion exÃ©cutÃ© mensuellement :
<br>

1. **Snowflake Infra Init**  
   Initialisation de l'infrastructure Snowflake (base, schÃ©mas, warehouse, rÃ´le, utilisateur).
2. **Scrape Links**  
   Scraping et rÃ©cupÃ©ration des liens sources.
3. **Upload to Stage**  
   Upload des fichiers bruts dans le stage Snowflake.
4. **Load to Table**  
   Chargement des donnÃ©es dans la table du schÃ©ma RAW.
5. **Run dbt Transformations**  
   Transformations dbt (STAGING puis FINAL).
6. **Run dbt Tests**  
   ExÃ©cution des tests dbt pour valider les modÃ¨les.
   
### Pipelines QualitÃ©

- **CodeQL Security Scan** <br> Analyse statique du code Python Ã  lâ€™aide de CodeQL afin de dÃ©tecter des vulnÃ©rabilitÃ©s sur chaque push ou pull request vers `dev` et `main`.
- **Dependabot Updates** <br> Mises Ã  jour automatisÃ©es des dÃ©pendances Python et GitHub Actions selon une planification trimestrielle.
- **pages-build-deployment** <br> DÃ©ploiement automatique de la documentation du projet via GitHub Pages.
- **Python Code Tests** <br> ExÃ©cution des tests unitaires Pytest sur chaque push ou pull request vers `dev` et `main`.
- **Release** <br> Versioning automatique, gÃ©nÃ©ration du changelog et publication des releases via Python Semantic Release sur chaque push ou pull request vers `main`.
- **SQL Code Quality** <br> Linting automatique du code SQL (modÃ¨les dbt et scripts Snowflake) avec SQLFluff sur chaque push ou pull request vers `dev` et `main`.
<br>
<br>


# ğŸ’» DÃ©marrage du Projet

## ğŸ“‹ PrÃ©requis

- Compte **Snowflake** avec droits **SECURITYADMIN** et **SYSADMIN**
- DÃ©pÃ´t **GitHub** avec **secrets configurÃ©s** (voir partie configuration)
- AccÃ¨s sources de donnÃ©es NYC Taxi : **https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page**
<br>


## ğŸš€ ExÃ©cution
- Automatique : tous les 1 du mois Ã  10h
- Manuel : via GitHub Actions interface
<br>


## âš™ï¸ Configuration
1. **Forkez** ce dÃ©pÃ´t : https://github.com/EliasMez/nyc-taxi-pipeline
<br>

2. **Ajoutez les secrets OBLIGATOIRES :** `Settings` > `Secrets and variables` > `Actions` > `Secrets` > `New repository secret` <br>

| Secret | Description |
|--------|-------------|
| `SNOWFLAKE_USER` | Nom d'utilisateur Snowflake |
| `SNOWFLAKE_PASSWORD` | Mot de passe utilisateur Snowflake |
| `SNOWFLAKE_ACCOUNT` | Identifiant du compte Snowflake |
| `PASSWORD_DEV` | Mot de passe de l'utilisateur de dÃ©veloppement |
<br>

3. **Personnalisez les variables OPTIONNELLES :** `Settings` > `Secrets and variables` > `Actions` > `Variables` > `New repository variables` <br>

| Variable | Description | Valeur par dÃ©faut |
|----------|-------------|-------------------|
| `WH_NAME` | Nom du data warehouse | `NYC_WH` |
| `DW_NAME` | Nom de la base de donnÃ©es | `NYC_TAXI_DW` |
| `RAW_SCHEMA` | SchÃ©ma des donnÃ©es brutes | `RAW` |
| `STAGING_SCHEMA` | SchÃ©ma des donnÃ©es nettoyÃ©es | `STAGING` |
| `FINAL_SCHEMA` | SchÃ©ma des donnÃ©es finales | `FINAL` |
| `PARQUET_FORMAT` | Format de fichier Parquet | `PARQUET_FORMAT` |
| `ROLE_TRANSFORMER` | RÃ´le pour les transformations | `TRANSFORMER` |
| `USER_DEV` | Utilisateur de dÃ©veloppement | `USER_DEV` |
| `METADATA_TABLE` | Table de mÃ©tadonnÃ©es | `FILE_LOADING_METADATA` |
| `RAW_TABLE` | Table des donnÃ©es brutes | `YELLOW_TAXI_TRIPS_RAW` |
| `STAGING_TABLE` | Table de staging | `YELLOW_TAXI_TRIPS_STG` |
| `LOGGER_LEVEL` | Niveau de logging | `INFO` |
| `SCRAPING_YEAR` | Date de dÃ©but du scraping (>2000 et <annÃ©e courante)| annÃ©e courante |
| `TIMEZONE` | Fuseau horaire qui dÃ©finit le dÃ©calage horaire par rapport Ã  UTC | `UTC` |
| `GH_RELEASE_TOKEN` | Token GitHub pour le versionnement automatique (nÃ©cessaire seulement si vous utilisez le workflow Release) | âš ï¸ non dÃ©fini |
<br>

âš ï¸ **Workflow Release (Semantic Release)**  
Le workflow **Release** nÃ©cessite un token GitHub (`GH_RELEASE_TOKEN`) pour fonctionner.  
Si ce token nâ€™est pas dÃ©fini, **le workflow Ã©chouera systÃ©matiquement** lors de lâ€™Ã©tape de publication.

**Option 1** : DÃ©sactiver le workflow *Release*
Si vous nâ€™avez pas besoin du versionnement automatique de code : `Actions` â†’ `Release` â†’ **Disable workflow**

**Option 2** : CrÃ©er un Personal Access Token (recommandÃ© si vous gardez le workflow)
1. Allez dans :  `Settings` â†’ `Developer settings` â†’ `Personal access tokens` â†’ **Tokens (classic)**  
2. CrÃ©ez un token avec les permissions `repo`  
3. Ajoutez-le comme secret : `Settings` â†’ `Secrets and variables` â†’ `Actions` â†’ **New repository secret**  
   - Nom : `GH_RELEASE_TOKEN`  
   - Valeur : *votre token*
<br>


## ğŸ”§ DÃ©pannage Rapide
- Ã‰chec connexion Snowflake : VÃ©rifier les secrets GitHub
- Timeout scraping : VÃ©rifier l'accÃ¨s aux URLs sources
- Erreur dbt : Consulter les logs dÃ©taillÃ©s du job
- Passer la valeur de la variable `LOGGER_LEVEL` Ã  `DEBUG` pour voir les logs dÃ©taillÃ©s
<br>
<br>


# ğŸ“ˆ Gouvernance des donnÃ©es

[![CodeQL](https://img.shields.io/badge/CodeQL-Security-0078D7?logo=github&logoColor=white)]()
[![Dependabot](https://img.shields.io/badge/Dependabot-Security-025E8C?logo=dependabot&logoColor=white)]()
[![Semantic Release](https://img.shields.io/badge/Semantic_Release-Versioning-494949?logo=semantic-release&logoColor=white)]()
[![SQLFluff](https://img.shields.io/badge/SQLFluff-Linting-000000?logo=sqlfluff&logoColor=white)]()

## ğŸ“Š Monitoring
- Logs dÃ©taillÃ©s dans GitHub Actions.  
- Alertes e-mail en cas dâ€™Ã©chec ou dâ€™annulation du workflow.  
- Suivi de lâ€™Ã©tat via une table de mÃ©tadonnÃ©es indiquant chaque Ã©tape (*scraped / staged / success / failed*).

## âœ… QualitÃ© des donnÃ©es
- Tests **dbt** garantissant lâ€™intÃ©gritÃ©, la cohÃ©rence et la validitÃ© des donnÃ©es.  
- Gestion des doublons via une vÃ©rification systÃ©matique des mÃ©tadonnÃ©es.

## ğŸ§ª QualitÃ© du code
- Tests unitaires avec **Pytest**.  
- Validation SQL avec **SQLFluff**.  
- Docstrings et doctests pour la documentation des fonctions.  
- <a href="https://eliasmez.github.io/nyc-taxi-pipeline/docstrings/">ğŸ“š Documentation technique</a>

## ğŸ” SÃ©curitÃ©
- Secrets chiffrÃ©s dans les logs.  
- Utilisation des **GitHub Secrets**.  
- Permissions minimales appliquÃ©es dans Snowflake.  
- Analyse statique avec **CodeQL**.  
- Mises Ã  jour de sÃ©curitÃ© automatisÃ©es via **Dependabot**.




